/**
 * Generate an AI-friendly robots.txt file.
 */
export function generateRobotsTxt(url: string, existingSitemap: boolean): string {
  const baseUrl = new URL(url).origin;

  let output = `# ============================================
# robots.txt â€” Generated by CIPWE
# The Web Vitals for the AI Web
# https://cipwe.com
# ============================================

# Allow all crawlers
User-agent: *
Allow: /
`;

  // Add sitemap reference
  if (existingSitemap) {
    output += `\nSitemap: ${baseUrl}/sitemap.xml\n`;
  }

  // Add AI-specific bot directives
  output += `
# ============================================
# AI Agent Directives
# Explicitly allow AI crawlers for better
# visibility in answer engines
# ============================================

# OpenAI / ChatGPT
User-agent: GPTBot
Allow: /

User-agent: ChatGPT-User
Allow: /

# Google AI (Gemini, AI Overviews)
User-agent: Google-Extended
Allow: /

User-agent: GoogleOther
Allow: /

# Anthropic / Claude
User-agent: anthropic-ai
Allow: /

User-agent: ClaudeBot
Allow: /

# Perplexity
User-agent: PerplexityBot
Allow: /

# Meta AI
User-agent: FacebookBot
Allow: /

# Microsoft / Bing AI
User-agent: Bingbot
Allow: /

# Common crawl (used for AI training)
User-agent: CCBot
Allow: /

# Cohere
User-agent: cohere-ai
Allow: /
`;

  if (existingSitemap) {
    output += `\nSitemap: ${baseUrl}/sitemap.xml\n`;
  } else {
    output += `\n# TODO: Add sitemap when available\n# Sitemap: ${baseUrl}/sitemap.xml\n`;
  }

  return output;
}
